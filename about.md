---
layout: page
title: About
permalink: /about/
published: true
---



### A Disambiguation Page of Allen Nie



<p style="text-align: center"><img src="https://github.com/windweller/windweller.github.io/blob/master/images/profile_pic.JPG?raw=true" style="width:50%"></p>



Three Stanford departments I've been affiliated with:

1. Computer Science Department (anie@cs.stanford.edu)
2. Symbolic Systems Program (anie@stanford.edu)
3. Department of Biomedical Data Science (BDS)

I earned my master of science degree from Symbolic Systems Program at Stanford University. My main area of focus is Natural Language Processing, but I work in other areas such as deep reinforcement learning, applied machine learning, information theory as well.

In 2016, I spent my first year working in Andrew Ng's [Stanford Machine Learning Group](https://stanfordmlgroup.github.io/) with Ziang Xie. The project centered around recurrent neural network regularizations and data augmentation. I became affiliated with Computer Science Department and received my CS email address during this time. 

In 2017 Summer, I worked with Noah Goodman in [CocoLab](https://cocolab.stanford.edu/) on using discourse markers to automatically construct supervised learning datasets. In the summer, I was a machine learning intern at a fast growing startup [Cresta AI](https://www.cresta.ai/) working with Zayd Enum (founder and Stanford EE PhD in Sebastian Thrun's group) and Russell Stewart (co-founder and Stanford CS PhD in Stefano Ermon's group).

In 2017 Winter, I accepted an offer to become a full-time research engineer at Stanford Biomedical Data Science Department in Medical School working with [James Zou](https://sites.google.com/site/jamesyzou/home). James Zou's primary area of focus is mathematical modeling of genetics, but he also worked on NLP fairness and medical AI problems. 

In 2018 Spring, I worked on a medical AI project that learns to automatically infer diagnostic codes in veterinary EHR. I presented this work at WeCNLP Summit later in the Fall.

In 2019, I accepted an offer to become a CS PhD student focusing on Artificial Intelligence at Stanford.

I'm constantly working on new projects and seeking to connect with people! Drop me an email if you want to talk about research or academic/industry life!


### Contact me

[aimingnie@gmail.com](mailto:aimingnie@gmail.com)


### Publications

- **DeepTag: inferring diagnoses from veterinary clinical notes.**, **A Nie**, A Zehnder, RL Page, AL Pineda, MA Rivas, CD Bustamante, J Zou., (2018). Nature (npj) Digital Medicine 1, Article: 60. \[[link](https://www.nature.com/articles/s41746-018-0067-8)\] \[[code](http://github.com/windweller/deeptag)\] \[[demo](http://anie.me/demo/deepvet)\]
- **DisSent: Sentence Representation Learning from Explicit Discourse Relations**. **Nie, A.**, Bennett, E.D., Goodman, N.D., (2017). To appear, ACL 2019. \[[link](https://arxiv.org/abs/1710.04334)\] \[[code](https://github.com/windweller/disextract)\]
- **Data Noising as Smoothing in Neural Network Sequence Models**. Ziang, X., Sida W., Jiwei L., Levy, D., **Nie A.**, Jurafsky, Dan & Ng, Andrew, (2016). 5th International Conference on Learning Representations (ICLR). Toulon, France. (Oral at BayLearn 2016) \[[link](https://arxiv.org/abs/1703.02573)\]
- **Representations of Time Affect Willingness to Wait for Future Rewards**. Thorstad, R., **Nie, A.**, & Wolff, P. (2015). 37th Annual Conference of the Cognitive Science Society. Pasadena, California. \[[link](http://psychology.emory.edu/cognition/wolff/papers/ThorstadNieWolff2015.pdf)\]
- **Computational Exploration to Linguistic Structures of Future, Classification and Categorization**. **Nie, A.**, Sheppard, J., Choi, J., Copley, B., Wolff, P., (2015). The North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Denver, Colorado. \[[link](http://www.aclweb.org/anthology/N15-2#page=178)\]


### Teaching

(assistant)
- 2018 Spring: CS224U Natural Language Understanding
- 2017 Spring: CS224S Spoken Language Processing
- 2016 Winter: CS224N Natural Language Processing
