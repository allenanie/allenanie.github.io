---
published: true
title: 2016 Edgy Paper Selection
layout: post
---


I decide to have a series of introductions for cutting edge papers. Those papaers are posted on Archive site like [arxiv.org](http://arxiv.org/). I recently subscribed to them. 

I will list those articles also based on themes, or relevancy, or (fancier) timelines. I won't discuss in great detail the content of the paper, but I'll leave my cursory comments.

## 2016 March

March is actually a great month, mostly due to the fact that ACL is finally wrapped up and we are seeing more papers being submitted. 

### Miscellaneous 

- **Topic Modeling Using Distributed Word Embeddings**

   by Ramandeep S Randhawa, Parag Jain, Gagan Madan
   
   University of Southern California, IIT Delhi
   
   Abstract: We propose a new algorithm for topic modeling, Vec2Topic, that identifies the main topics in a corpus using semantic information captured via high-dimensional distributed word embeddings. Our technique is unsupervised and generates a list of topics ranked with respect to importance. We find that it works better than existing topic modeling techniques such as Latent Dirichlet Allocation for identifying key topics in user-generated content, such as emails, chats, etc., where topics are diffused across the corpus. We also find that Vec2Topic works equally well for non-user generated content, such as papers, reports, etc., and for small corpora such as a single-document.
   
   link: [http://arxiv.org/abs/1603.04747](http://arxiv.org/abs/1603.04747)
   
   Comments: Might be interesting to check out, a replacement for LDA
   
- **The Computational Power of Dynamic Bayesian Networks**

   by Joshua Brulé
   
   University of Maryland
   
   Abstract: This paper considers the computational power of constant size, dynamic Bayesian networks. Although discrete dynamic Bayesian networks are no more powerful than hidden Markov models, dynamic Bayesian networks with continuous random variables and discrete children of continuous parents are capable of performing Turing-complete computation. With modified versions of existing algorithms for belief propagation, such a simulation can be carried out in real time. This result suggests that dynamic Bayesian networks may be more powerful than previously considered. Relationships to causal models and recurrent neural networks are also discussed.
   
   link: [http://arxiv.org/abs/1603.06125](http://arxiv.org/abs/1603.06125)
   
   Comments: Dynamic Bayesian network is Turing-complete. Maybe it can give neural network a run for its money??

### Computer Vision

- **Object Contour Detection with a Fully Convolutional Encoder-Decoder Network**

   by Jimei Yang, Brian Price, Scott Cohen, Honglak Lee, Ming-Hsuan Yang
   
   Adobe Research
   
   Abstract: We develop a deep learning algorithm for contour detection with a fully convolutional encoder-decoder network. Different from previous low-level edge detection, our algorithm focuses on detecting higher-level object contours. Our network is trained end-to-end on PASCAL VOC with refined ground truth from inaccurate polygon annotations, yielding much higher precision in object contour detection than previous methods. We find that the learned model generalizes well to unseen object classes from the same super-categories on MS COCO and can match state-of-the-art edge detection on BSDS500 with fine-tuning. By combining with the multiscale combinatorial grouping algorithm, our method can generate high-quality segmented object proposals, which significantly advance the state-of-the-art on PASCAL VOC (improving average recall from 0.62 to 0.67) with a relatively small amount of candidates (∼1660 per image).
   
   link: [http://arxiv.org/abs/1603.04530](http://arxiv.org/abs/1603.04530)
   
   Comments: We have seen RNN encoder-decoder network, but what about CNN encoder-decoder? This might provide some answer. The encoder part is a normal CNN to condense the spatial information, the decoder part is a "deconv" network.

- ** (Image) Segmentation from Natural Language Expressions**

   by Ronghang Hu, Marcus Rohrbach, Trevor Darrell
   
   Berkeley
   
   Abstract: In this paper we approach the novel problem of segmenting an image based on a natural language expression. This is different from traditional semantic segmentation over a predefined set of semantic classes, as e.g., the phrase "two men sitting on the right bench" requires segmenting only the two people on the right bench and no one standing or sitting on another bench. Previous approaches suitable for this task were limited to a fixed set of categories and/or rectangular regions. To produce pixelwise segmentation for the language expression, we propose an end-to-end trainable recurrent and convolutional network model that jointly learns to process visual and linguistic information. In our model, a recurrent LSTM network is used to encode the referential expression into a vector representation, and a fully convolutional network is used to a extract a spatial feature map from the image and output a spatial response map for the target object. We demonstrate on a benchmark dataset that our model can produce quality segmentation output from the natural language expression, and outperforms baseline methods by a large margin.
   
   link: [http://arxiv.org/abs/1603.06180](http://arxiv.org/abs/1603.06180)
   
   Comments: Very interesting article. A little bit too long. It could be useful for any kind of image-mixed-with-language application (such as AR or VR).
   

### NLP

- **End-to-End Attention-based Large Vocabulary Speech Recognition**

   by Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, Yoshua Bengio
   
   University of Montreal, Bengio Group
   
   Abstract: Many of the current state-of-the-art Large Vocabulary Continuous Speech Recognition Systems (LVCSR) are hybrids of neural networks and Hidden Markov Models (HMMs). Most of these systems contain separate components that deal with the acoustic modelling, language modelling and sequence decoding. We investigate a more direct approach in which the HMM is replaced with a Recurrent Neural Network (RNN) that performs sequence prediction directly at the character level. Alignment between the input features and the desired character sequence is learned automatically by an attention mechanism built into the RNN. For each predicted character, the attention mechanism scans the input sequence and chooses relevant frames. We propose two methods to speed up this operation: limiting the scan to a subset of most promising frames and pooling over time the information contained in neighboring frames, thereby reducing source sequence length. Integrating an n-gram language model into the decoding process yields recognition accuracies similar to other HMM-free RNN-based approaches.
   
   link: [http://arxiv.org/abs/1508.04395](http://arxiv.org/abs/1508.04395)
   
   Comments: This is a natural extension to what Bahdanau worked on in attention-based neural machine translation (he is the one who came up with attention: [NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE](http://arxiv.org/pdf/1409.0473v6.pdf)). Now they are applying the model to speech recognition.
   
- **Tree-to-Sequence Attentional Neural Machine Translation**

   by Akiko Eriguchi, Kazuma Hashimoto, Yoshimasa Tsuruoka
   
   The University of Tokyo
   
   Abstract: Most of the existing neural machine translation (NMT) models focus on the conversion of sequential data and do not directly take syntax into consideration. We propose a novel end-to-end syntactic NMT model, extending a sequence-to-sequence model with the source-side phrase structure. Our model has an attention mechanism that enables the decoder to generate a translated word while softly aligning it with phrases as well as words of the source sentence. Experimental results on the WAT'15 English-to-Japanese dataset demonstrate that our proposed model outperforms sequence-to-sequence attentional NMT models and compares favorably with the state-of-the-art tree-to-string SMT system.
   
   link: [http://arxiv.org/abs/1603.06075](http://arxiv.org/abs/1603.06075)
   
   Comments: I think there are two camps of the deep learning NLP right now. One camp (mostly from the big three Deep Learning groups) is trying to be agnostic to linguistic knowledge. They are developing character-based models to learn language from ground up. Another camp is to try their best to incorporate linguistic structure or knowledge into deep learning framework. This paper is a beautiful example of the latter. It shows how people the proper way to bake syntax into neural network models.
   
- **How Transferable are Neural Networks in NLP Applications?**

   by Lili Mou, Zhao Meng, Rui Yan, Ge Li, Yan Xu, Lu Zhang, Zhi Jin
   
   Peking University
   
   Abstract: Transfer learning is aimed to make use of valuable knowledge in a source domain to help the model performance in a target domain. It is particularly important to neural networks because neural models are very likely to be overfitting. In some fields like image processing, many studies have shown the effectiveness of neural network-based transfer learning. For neural NLP, however, existing studies have only casually applied transfer learning, and conclusions are inconsistent. In this paper, we conduct a series of empirical studies and provide an illuminating picture on the transferability of neural networks in NLP.

   
   link: [http://arxiv.org/abs/1603.06111](http://arxiv.org/abs/1603.06111)
   
   Comments: This article is building from the transfer learning literature in Computer Vision arena. I skipped the paper and read the conclusion and it turns out to be related to how similar two corpuses or two genres are. Seems to be a bit platitudinous.

- **A Character-level Decoder without Explicit Segmentation for Neural Machine Translation**

   by Junyoung Chung, Kyunghyun Cho, Yoshua Bengio
   
   University of Montreal, New York University
   
   Abstract: The existing machine translation systems, whether phrase-based or neural, have relied almost exclusively on word-level modelling with explicit segmentation. In this paper, we ask a fundamental question: can neural machine translation generate a character sequence without any explicit segmentation? To answer this question, we evaluate an attention-based encoder-decoder with a subword-level encoder and a character-level decoder on four language pairs--En-Cs, En-De, En-Ru and En-Fi-- using the parallel corpora from WMT'15. Our experiments show that the models with a character-level decoder outperform the ones with a subword-level decoder on all of the four language pairs. Furthermore, the ensembles of neural models with a character-level decoder outperform the state-of-the-art non-neural machine translation systems on En-Cs, En-De and En-Fi and perform comparably on En-Ru.
   
   link: [http://arxiv.org/abs/1603.06147](http://arxiv.org/abs/1603.06147)
   
   Comments: Take it from the University of Tokyo's tree-based article, this article is running off to the end of the other spectrum. For this paper, they only investigated generating target sentence character-by-character, but they suggest future literature to investigate reading in source sentences character-by-character. (They did slightly better than state-of-the-art with an ensemble model)
   
- **A Persona-Based Neural Conversation Model**

   by Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan
   
   Stanford University (Jurafsky Group), Microsoft Research
   
   Abstract: We present persona-based models for handling the issue of speaker consistency in neural response generation. A speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style. A dyadic speaker-addressee model captures properties of interactions between two interlocutors. Our models yield qualitative performance improvements in both perplexity and BLEU scores over baseline sequence-to-sequence models, with similar gain in speaker consistency as measured by human judges.
   
   link: [http://arxiv.org/abs/1603.06155](http://arxiv.org/abs/1603.06155)
   
   Comments: (First of all, I talked with Jianfeng Gao at NAACL 2015 lol, glad to see his name here) It's just a fun paper to read. The proposed model is straight-forward and easy to understand. It could be applied to multiple things.
   








   